{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta encontrada: data/luffy\n",
      "Pasta encontrada: data/zoro\n",
      "Pasta encontrada: data/nami\n",
      "Pasta encontrada: data/usopp\n",
      "Pasta encontrada: data/sanji\n",
      "Pasta encontrada: data/chopper\n",
      "Pasta encontrada: data/robin\n",
      "Pasta encontrada: data/franky\n",
      "Pasta encontrada: data/brook\n",
      "Pasta encontrada: data/jinbei\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marie\\OneDrive\\Área de Trabalho\\one_piece_classification\\.venv\\Lib\\site-packages\\PIL\\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados pré-processados e salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_dir = 'data/'\n",
    "characters = ['luffy', 'zoro', 'nami', 'usopp', 'sanji', 'chopper', 'robin', 'franky', 'brook', 'jinbei']\n",
    "\n",
    "# verificando se todas as pastas existem\n",
    "for character in characters:\n",
    "    character_dir = os.path.join(data_dir, character)\n",
    "    if not os.path.exists(character_dir):\n",
    "        print(f\"Pasta não encontrada: {character_dir}\")\n",
    "    else:\n",
    "        print(f\"Pasta encontrada: {character_dir}\")\n",
    "        \n",
    "        \n",
    "# lista para armazenar imagens e labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# carregar imagens e labels\n",
    "for idx, character in enumerate(characters):\n",
    "    character_dir = os.path.join(data_dir, character)\n",
    "    for img_name in os.listdir(character_dir):\n",
    "        img_path = os.path.join(character_dir, img_name)\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(128, 128))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        images.append(img_array)\n",
    "        labels.append(idx)\n",
    "\n",
    "# converter listas para arrays numpy\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# normalizar as imagens\n",
    "images = images / 255.0\n",
    "\n",
    "# Ddividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# salvar os dados pré-processados\n",
    "np.save('data/X_train.npy', X_train)\n",
    "np.save('data/X_test.npy', X_test)\n",
    "np.save('data/y_train.npy', y_train)\n",
    "np.save('data/y_test.npy', y_test)\n",
    "\n",
    "print(\"Dados pré-processados e salvos com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
